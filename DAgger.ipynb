{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "> <ipython-input-1-82d102caf972>(88)<module>()->None\n",
      "-> pdb.set_trace()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  env._robot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<rlbench.backend.robot.Robot object at 0x7f777f74bfd0>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  env._robot.get_joint_positions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'Robot' object has no attribute 'get_joint_positions'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  env._robot.get_joint_positions()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'Robot' object has no attribute 'get_joint_positions'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  env._robot.arn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'Robot' object has no attribute 'arn'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  env._robot.arm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyrep.robots.arms.panda.Panda object at 0x7f777f74bc18>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  env._task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<rlbench.tasks.reach_target.ReachTarget object at 0x7f777f74bb70>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  env._task.target\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'ReachTarget' object has no attribute 'target'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  env._task.init_task()\n",
      "(Pdb)  env._task.target\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyrep.objects.shape.Shape object at 0x7f771ea306d8>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  env._task.target.get_position()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0.25      , 0.        , 0.87699974])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  env._task.robot.get_tip().get_position()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'Robot' object has no attribute 'get_tip'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  env._task.robot.arm.get_tip.get_position()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'function' object has no attribute 'get_position'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  env._task.robot.arm.get_tip()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyrep.objects.dummy.Dummy object at 0x7f777f74be10>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  env._task.robot.arm.get_tip().get_position()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([ 0.27810264, -0.0081704 ,  1.47322607])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DAgger Implementation for RLBench\n",
    "# Paper: https://www.ri.cmu.edu/pub_files/2011/4/Ross-AISTATS11-NoRegret.pdf\n",
    "# Author: Krishan Rana\n",
    "\n",
    "from rlbench.environment import Environment\n",
    "from rlbench.action_modes import ArmActionMode, ActionMode\n",
    "from rlbench.observation_config import ObservationConfig\n",
    "from rlbench.tasks import ReachTarget, PushButtons\n",
    "import numpy as np\n",
    "import pdb\n",
    "import numpy as np\n",
    "from spatialmath import SE3, SO3\n",
    "import pdb\n",
    "import roboticstoolbox as rb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "class RRMC():\n",
    "    \n",
    "    def fkine(self):\n",
    "        # Tip pose in world coordinate frame\n",
    "        wTe = SE3(env._task.robot.arm.get_tip().get_position())*SE3.Eul(env._task.robot.arm.get_tip().get_orientation())\n",
    "        return wTe\n",
    "    \n",
    "    def target_pose(self):\n",
    "        # Target pose in world coordinate frame\n",
    "        wTt = SE3(env._task.target.get_position())*SE3.Eul(env._task.target.get_orientation())\n",
    "        return wTt\n",
    "    \n",
    "    def compute_action(self, target):\n",
    "        \n",
    "        try:\n",
    "            self.panda.q = self.env.agent.get_joint_positions()\n",
    "            v = self.p_servo(self.panda.fkine(self.panda.q), self.target_pose(), gain=0.3)\n",
    "            v[3:] *= 10\n",
    "            action = np.linalg.pinv(self.panda.jacobe(self.panda.q)) @ v\n",
    "\n",
    "        except np.linalg.LinAlgError:\n",
    "            action = np.zeros(self.env.n)\n",
    "            #self.env.r.fail = True\n",
    "            print('Fail')\n",
    "\n",
    "        return action\n",
    "        \n",
    "        ee_position = env._task.robot.arm.get_tip().get_position() # (x,y,z) position of the tip\n",
    "        target_position = env._task.target.get_position() # (x,y,z) position of the target\n",
    "        q = env._target.robot.arm.get_joint_positions()\n",
    "        \n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, act_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(2704, 520)\n",
    "        self.fc2 = nn.Linear(520,108)\n",
    "        self.fc3 = nn.Linear(108,54)\n",
    "        self.fc4 = nn.Linear(54, act_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = torch.tanh(self.fc4(x))\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pi = Model(env_task.action_size).to(device)\n",
    "        \n",
    "    def train(self):\n",
    "        print(\"Training...\")\n",
    "        batch = random.sample(experience_dataset, 32)\n",
    "        batch_obs = torch.as_tensor([demo[1] for demo in batch], dtype=torch.float32).to(device).permute(0,3,1,2)\n",
    "        predicted_actions = self.pi(batch_obs)\n",
    "        ground_truth_actions = torch.as_tensor([demo[0] for demo in batch], dtype=torch.float32).to(device).detach()\n",
    "        loss = criterion(predicted_actions, ground_truth_actions)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    def get_action(self, obs):\n",
    "        with torch.no_grad():\n",
    "            obs = torch.as_tensor(obs, dtype=torch.float32).to(device).unsqueeze(0)\n",
    "            obs = obs.permute(0,3,1,2)\n",
    "            act = self.pi(obs).cpu().numpy()[0]\n",
    "            return act\n",
    "    \n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "obs_config = ObservationConfig()\n",
    "obs_config.set_all(False)\n",
    "obs_config.wrist_camera.rgb = True\n",
    "obs_config.joint_positions  = True\n",
    "\n",
    "action_mode = ActionMode(ArmActionMode.ABS_JOINT_VELOCITY)\n",
    "env_task = Environment(action_mode, '', obs_config, False)\n",
    "env_task.launch()\n",
    "\n",
    "env = env_task.get_task(ReachTarget)\n",
    "agent = Agent()\n",
    "\n",
    "pdb.set_trace()\n",
    "\n",
    "obs = env.reset()\n",
    "#control_prior = scripted_prior()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(agent.pi.parameters(), lr=0.01, momentum=0.9)\n",
    "total_steps = 1000\n",
    "episode_length = 40\n",
    "experience_dataset = []\n",
    "\n",
    "descriptions, state = env.reset()\n",
    "obs = state.wrist_rgb\n",
    "q = state.joint_positions\n",
    "\n",
    "for i in range(total_steps):\n",
    "    if i%episode_length == 0 and i > 100:\n",
    "        descriptions, state = env.reset()\n",
    "        agent.train()\n",
    "    action = agent.get_action(obs)\n",
    "    next_state, reward, done = env.step(action)\n",
    "    nobs = state.wrist_rgb\n",
    "    q = state.joint_positions\n",
    "    #demos.append([control_prior.act(obs), obs])\n",
    "    experience_dataset.append([action, obs])\n",
    "    obs = nobs\n",
    "    \n",
    "print('Done')\n",
    "env.shutdown()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RRMC_controller():\n",
    "\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.panda = rb.models.DH.Panda()\n",
    "\n",
    "    def p_servo(self, wTe, wTep, gain=2):\n",
    "      \n",
    "        if not isinstance(wTe, SE3):\n",
    "            wTe = SE3(wTe)\n",
    "\n",
    "        if not isinstance(wTep, SE3):\n",
    "            wTep = SE3(wTep)\n",
    "\n",
    "        # Pose difference\n",
    "        eTep = wTe.inv() * wTep\n",
    "        # Translational velocity error\n",
    "        ev = eTep.t\n",
    "        # Angular velocity error\n",
    "        ew = eTep.rpy() * np.pi/180\n",
    "        #ew = [0,0,0]\n",
    "\n",
    "        # Form error vector\n",
    "        e = np.r_[ev, ew]\n",
    "        dist = np.array(self.env.agent.get_tip().get_position()) - np.array(self.env.target.get_position())\n",
    "        v = gain * e\n",
    "        \n",
    "        return v\n",
    "    \n",
    "    \n",
    "    def target_pose(self):\n",
    "        # Target pose in world coordinate frame\n",
    "        pose = SE3(self.env.target.get_position())*SE3.Eul(self.env.target.get_orientation())\n",
    "        return pose\n",
    "\n",
    "\n",
    "    def compute_action(self, obs, gain=1):\n",
    "        \n",
    "        q = obs.joint_positions\n",
    "\n",
    "        try:\n",
    "            self.panda.q = self.env.agent.get_joint_positions()\n",
    "            v = self.p_servo(self.panda.fkine(self.panda.q), self.target_pose(), gain=0.3)\n",
    "            v[3:] *= 10\n",
    "            action = np.linalg.pinv(self.panda.jacobe(self.panda.q)) @ v\n",
    "\n",
    "        except np.linalg.LinAlgError:\n",
    "            action = np.zeros(self.env.n)\n",
    "            #self.env.r.fail = True\n",
    "            print('Fail')\n",
    "\n",
    "        return action\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
